{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils import mypreprocess, util_functions, eff_unet\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from mcdropout import MCDropout2D\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EffUNet(\n",
       "  (start_conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (down_block_2): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_3): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_4): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_5): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block_4): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(432, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_3): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(296, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_2): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_1a): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_1b): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (head_conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/work/ovens_lab/thaonguyen/image_segmentation/best_model.pt' \n",
    "model = eff_unet.EffUNet(in_channels=1, classes=1)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of batches: 941, batch shape: torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "inference_dir = '/work/ovens_lab/thaonguyen/image_segmentation/2d_dataset/testing' \n",
    "inference_transformer = transforms.Compose([transforms.ToTensor(), \n",
    "                                            transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True)])\n",
    "inference_loader = mypreprocess.create_data_loaders(path_dir=inference_dir, image_dir='images', \n",
    "                                                    label_dir='labels', \n",
    "                                                    data_transformer=inference_transformer, \n",
    "                                                    batch_size=1, split_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EffUNet(\n",
       "  (start_conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (down_block_2): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_3): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_4): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_block_5): Sequential(\n",
       "    (0): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (expand_conv): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (depthwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (se_block): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "      (pointwise_conv): Sequential(\n",
       "        (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_block_4): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(432, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_3): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(296, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_2): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_1a): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (up_block_1b): DecoderBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MCDropout2D()\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (head_conv): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient2_modified(target, preds):\n",
    "    preds_flat = preds.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "\n",
    "    intersection = (preds_flat * target_flat).sum()\n",
    "    set_sum = preds_flat.sum() + target_flat.sum()\n",
    "\n",
    "    dice = (2 * intersection + 1e-8) / (set_sum + 1e-8) \n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions together with original image and ground truth\n",
    "def show_image_modified(image, mask, pred_image=None, path_dir=None, filename=None, iou=None, dice_score=None):\n",
    "    image = image.squeeze() \n",
    "    mask = mask.squeeze() \n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    if pred_image is not None:\n",
    "        ax1 = plt.subplot(1, 3, 1)\n",
    "        ax2 = plt.subplot(1, 3, 2)\n",
    "        ax3 = plt.subplot(1, 3, 3)\n",
    "    else:\n",
    "        ax1 = plt.subplot(1, 2, 1)\n",
    "        ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "    ax1.set_title('IMAGE')\n",
    "    ax1.imshow(image, cmap='gray')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.set_title('GROUND TRUTH')\n",
    "    ax2.imshow(mask, cmap='gray')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    if pred_image is not None and iou is not None and dice_score is not None:\n",
    "        pred_image = pred_image.squeeze()\n",
    "        ax3.imshow(pred_image, cmap='gray')\n",
    "        ax3.set_title('MODEL OUTPUT')\n",
    "        ax3.axis('off')\n",
    "        ax3.text(5, 5, f'IoU: {iou:.2f}, Dice: {dice_score:.2f}', color='white', fontsize=8, backgroundcolor='black')\n",
    "\n",
    "    if path_dir is not None and filename is not None:\n",
    "        full_path = os.path.join(path_dir, filename)\n",
    "        plt.savefig(full_path, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save uncertainty map together with the original image\n",
    "def show_uncertainty_map(original_image, uncertainty_map, path, filename, avg_iou, avg_dice):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax1.imshow(original_image, cmap='gray')\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    ax2.imshow(uncertainty_map, cmap='gray')\n",
    "    ax2.set_title('Uncertainty Map')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.figtext(0.5, 0.01, f\"Average IoU: {avg_iou:.4f}, Average Dice: {avg_dice:.4f}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "    combined_save_path = os.path.join(path, filename)\n",
    "    plt.savefig(combined_save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction only\n",
    "def save_prediction(pred_image, path_dir, filename):\n",
    "    if pred_image is not None:\n",
    "        plt.figure(figsize=(512 / 100, 512 / 100)) \n",
    "        plt.imshow(pred_image.squeeze(), cmap='gray') \n",
    "        plt.axis('off')\n",
    "\n",
    "        if path_dir is not None and filename is not None:\n",
    "            full_path = os.path.join(path_dir, filename)\n",
    "            plt.savefig(full_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the uncertainty map only\n",
    "def save_uncertainty_map(uncertainty_map, path, filename):\n",
    "    plt.figure(figsize=(512 / 100, 512 / 100)) \n",
    "\n",
    "    plt.imshow(uncertainty_map, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    combined_save_path = os.path.join(path, filename)\n",
    "    plt.savefig(combined_save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate MC Dropout for inference\n",
    "MCDropout2D.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(prob_maps):\n",
    "    return -np.sum(prob_maps * np.log(prob_maps + 1e-8), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_passes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_dice_per_pass(pred_mask, true_mask):\n",
    "    iou = util_functions.calculate_IoU(pred_mask, true_mask)\n",
    "    dice_score = dice_coefficient2_modified(true_mask, pred_mask)\n",
    "    return iou.item(), dice_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined version of predictions and uncertainty map\n",
    "\n",
    "# mc_prediction_folder = '/work/ovens_lab/thaonguyen/image_segmentation/mc_predictions(combined)'\n",
    "# uncertainty_map_folder = '/work/ovens_lab/thaonguyen/image_segmentation/uncertainty_map(combined)'\n",
    "# os.makedirs(mc_prediction_folder, exist_ok=True)\n",
    "# os.makedirs(uncertainty_map_folder, exist_ok=True)\n",
    "\n",
    "# total_iou = 0.0\n",
    "# total_dice = 0.0\n",
    "# num_images = 0\n",
    "\n",
    "# for idx, (images, true_masks, index_tuple) in tqdm(enumerate(inference_loader), total=len(inference_loader.dataset)):\n",
    "#     images = images.to(device)\n",
    "#     true_masks = true_masks.to(device)\n",
    "#     image_index, slice_index = map(lambda x: x.item(), index_tuple)\n",
    "\n",
    "#     prediction_filename = f'image_{image_index:04d}_{slice_index:04d}.png'\n",
    "#     uncertainty_filename = f'image_{image_index:04d}_{slice_index:04d}_uncertainty.png'\n",
    "\n",
    "#     uncertainty_file_path = os.path.join(uncertainty_map_folder, uncertainty_filename)\n",
    "#     if os.path.exists(uncertainty_file_path):\n",
    "#         continue \n",
    "\n",
    "#     pass_iou = 0.0\n",
    "#     pass_dice = 0.0\n",
    "#     prob_maps = []\n",
    "\n",
    "#     for pass_idx in range(num_passes):\n",
    "#         with torch.no_grad():\n",
    "#             logits_mask = model(images)\n",
    "#             pred_mask = torch.sigmoid(logits_mask)\n",
    "#             pred_mask_cpu = pred_mask[0].detach().cpu().squeeze().numpy()\n",
    "#             prob_maps.append(pred_mask_cpu)\n",
    "\n",
    "#             iou, dice_score = calculate_iou_dice_per_pass(pred_mask, true_masks)\n",
    "#             pass_iou += iou\n",
    "#             pass_dice += dice_score\n",
    "\n",
    "#             pass_folder = os.path.join(mc_prediction_folder, f'pass{pass_idx+1}')\n",
    "#             os.makedirs(pass_folder, exist_ok=True)\n",
    "#             save_path = os.path.join(pass_folder, prediction_filename)\n",
    "#             show_image_modified(images[0].detach().cpu().squeeze(), true_masks[0].detach().cpu().squeeze(), \n",
    "#                                 pred_mask_cpu, path_dir=pass_folder, filename=prediction_filename, \n",
    "#                                 iou=iou, dice_score=dice_score)\n",
    "\n",
    "#     avg_iou = pass_iou / num_passes\n",
    "#     avg_dice = pass_dice / num_passes\n",
    "\n",
    "#     total_iou += avg_iou\n",
    "#     total_dice += avg_dice\n",
    "#     num_images += 1\n",
    "\n",
    "#     prob_maps = np.stack(prob_maps, axis=0)\n",
    "#     uncertainty_map = calculate_entropy(prob_maps)\n",
    "#     original_image = images[0].detach().cpu().squeeze().numpy()\n",
    "#     show_uncertainty_map(original_image, uncertainty_map, uncertainty_map_folder, uncertainty_filename, avg_iou, avg_dice)\n",
    "\n",
    "# overall_iou = total_iou / num_images\n",
    "# overall_dice = total_dice / num_images\n",
    "# print(f\"Overall IoU: {overall_iou:.4f}, Overall Dice Score: {overall_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/941 [00:00<?, ?it/s]/home/phuongthao.nguyen/software/miniconda3/envs/ieee/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 941/941 [20:20<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall IoU: nan, Overall Dice Score: 0.4527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the prediction and uncertainty map only\n",
    "mc_prediction_folder = '/work/ovens_lab/thaonguyen/image_segmentation/mc_predictions'\n",
    "uncertainty_map_folder = '/work/ovens_lab/thaonguyen/image_segmentation/uncertainty_map'\n",
    "os.makedirs(mc_prediction_folder, exist_ok=True)\n",
    "os.makedirs(uncertainty_map_folder, exist_ok=True)\n",
    "\n",
    "total_iou = 0.0\n",
    "total_dice = 0.0\n",
    "num_images = 0\n",
    "\n",
    "for idx, (images, true_masks, index_tuple) in tqdm(enumerate(inference_loader), total=len(inference_loader.dataset)):\n",
    "    images = images.to(device)\n",
    "    true_masks = true_masks.to(device)\n",
    "    image_index, slice_index = map(lambda x: x.item(), index_tuple)\n",
    "\n",
    "    prediction_filename = f'image_{image_index:04d}_{slice_index:04d}.png'\n",
    "    uncertainty_filename = f'image_{image_index:04d}_{slice_index:04d}_uncertainty.png'\n",
    "\n",
    "    uncertainty_file_path = os.path.join(uncertainty_map_folder, uncertainty_filename)\n",
    "    if os.path.exists(uncertainty_file_path):\n",
    "        continue \n",
    "\n",
    "    pass_iou = 0.0\n",
    "    pass_dice = 0.0\n",
    "    prob_maps = []\n",
    "\n",
    "    for pass_idx in range(num_passes):\n",
    "        with torch.no_grad():\n",
    "            logits_mask = model(images)\n",
    "            pred_mask = torch.sigmoid(logits_mask)\n",
    "            pred_mask_cpu = pred_mask[0].detach().cpu().squeeze().numpy()\n",
    "            prob_maps.append(pred_mask_cpu)\n",
    "\n",
    "            iou, dice_score = calculate_iou_dice_per_pass(pred_mask, true_masks)\n",
    "            pass_iou += iou\n",
    "            pass_dice += dice_score\n",
    "\n",
    "            pass_folder = os.path.join(mc_prediction_folder, f'pass{pass_idx+1}')\n",
    "            os.makedirs(pass_folder, exist_ok=True)\n",
    "            save_path = os.path.join(pass_folder, prediction_filename)\n",
    "            save_prediction(pred_mask_cpu, pass_folder, prediction_filename) \n",
    "\n",
    "    avg_iou = pass_iou / num_passes\n",
    "    avg_dice = pass_dice / num_passes\n",
    "\n",
    "    total_iou += avg_iou\n",
    "    total_dice += avg_dice\n",
    "    num_images += 1\n",
    "\n",
    "    prob_maps = np.stack(prob_maps, axis=0)\n",
    "    uncertainty_map = calculate_entropy(prob_maps)\n",
    "    original_image = images[0].detach().cpu().squeeze().numpy()\n",
    "    save_uncertainty_map(uncertainty_map, uncertainty_map_folder, uncertainty_filename)  \n",
    "\n",
    "overall_iou = total_iou / num_images\n",
    "overall_dice = total_dice / num_images\n",
    "print(f\"Overall IoU: {overall_iou:.4f}, Overall Dice Score: {overall_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 941/941 [00:08<00:00, 108.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D uncertainty NIfTI files created.\n"
     ]
    }
   ],
   "source": [
    "# Combine 2d uncertainty maps into 3d \n",
    "\n",
    "def load_and_combine_uncertainty_slices_to_nifti(uncertainty_map_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Dictionary to hold uncertainty slices for each image\n",
    "    image_uncertainty_slices = {}\n",
    "\n",
    "    # Iterate over uncertainty map files and group slices by image\n",
    "    for file in tqdm(sorted(os.listdir(uncertainty_map_folder))):\n",
    "        if file.endswith('_uncertainty.png'):\n",
    "            parts = file.split('_')\n",
    "            image_index = int(parts[1])\n",
    "            slice_index = int(parts[2])\n",
    "            slice_path = os.path.join(uncertainty_map_folder, file)\n",
    "            slice_data = io.imread(slice_path, as_gray=True)\n",
    "\n",
    "            if image_index not in image_uncertainty_slices:\n",
    "                image_uncertainty_slices[image_index] = {}\n",
    "            image_uncertainty_slices[image_index][slice_index] = slice_data\n",
    "\n",
    "    # Process each image group\n",
    "    for image_index in image_uncertainty_slices:\n",
    "        slices = [image_uncertainty_slices[image_index][i] for i in sorted(image_uncertainty_slices[image_index])]\n",
    "        image_3d_uncertainty = np.stack(slices, axis=-1)\n",
    "\n",
    "        nifti_path = os.path.join(output_folder, f'image_{image_index:04d}_uncertainty.nii.gz')\n",
    "        nifti_img = nib.Nifti1Image(image_3d_uncertainty, np.eye(4))\n",
    "        nib.save(nifti_img, nifti_path)\n",
    "\n",
    "    print(\"3D uncertainty NIfTI files created.\")\n",
    "\n",
    "uncertainty_map_folder = '/work/ovens_lab/thaonguyen/image_segmentation/uncertainty_map'\n",
    "output_folder = '/work/ovens_lab/thaonguyen/image_segmentation/3d_uncertainty_map'\n",
    "load_and_combine_uncertainty_slices_to_nifti(uncertainty_map_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
