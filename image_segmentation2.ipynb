{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/sinaziaee/mini_conda/miniconda3/envs/test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from torchmetrics.classification import Dice\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch\n",
    "from utils import unet, mypreprocess, util_functions, eff_unet, eff_unet2, dataset3d, dataset2d\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "import gc\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from mcdropout import MCDropout2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = '/scratch/student/sinaziaee/datasets/3d_dataset'\n",
    "# train_dir = os.path.join(base_path, 'training')\n",
    "# valid_dir = os.path.join(base_path, 'validation')\n",
    "# test_dir = os.path.join(base_path, 'testing')\n",
    "# # IMG_SIZE = 512\n",
    "# BATCH_SIZE = 80\n",
    "\n",
    "# transform_input, transform_output = util_functions.custom_transformers(scale=(0.5, 2), \n",
    "#                                                     contrast=(0.5, 2), brightness=(0.5, 1.5), rotation=180, blur=1)\n",
    "# aug1_dataset = my_dataset.SegmentationDataset(input_root=f'{train_dir}/images/',target_root=f'{train_dir}/labels/',\n",
    "#                                transform_input= transform_input, transform_target=transform_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images, training: 41013 , validation 1047  testing: 1063\n"
     ]
    }
   ],
   "source": [
    "base_path = '/scratch/student/sinaziaee/datasets/2d_dataset/'\n",
    "train_dir = os.path.join(base_path, 'training')\n",
    "valid_dir = os.path.join(base_path, 'validation')\n",
    "test_dir = os.path.join(base_path, 'testing')\n",
    "# IMG_SIZE = 512\n",
    "BATCH_SIZE = 80\n",
    "\n",
    "transform_input, transform_output = util_functions.custom_transformers(scale=(0.5, 2), \n",
    "                                                    contrast=(0.5, 2), brightness=(0.5, 1.5), rotation=180, blur=1)\n",
    "valid_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "aug1_dataset = dataset2d.SegmentationDataset(input_root=f'{train_dir}/images/',target_root=f'{train_dir}/labels/',\n",
    "                               transform_input= transform_input, transform_target=transform_output)\n",
    "transform_input, transform_output = util_functions.custom_transformers(scale=(0.7, 1.4), \n",
    "                                                    brightness=(0.75, 1.25), contrast=(0.5, 2), rotation=360, blur=1)\n",
    "aug2_dataset = dataset2d.SegmentationDataset(input_root=f'{train_dir}/images/',target_root=f'{train_dir}/labels/',\n",
    "                               transform_input= transform_input, transform_target=transform_output)\n",
    "plain_train_dataset = dataset2d.SegmentationDataset(input_root=f'{train_dir}/images/',target_root=f'{train_dir}/labels/',\n",
    "                               transform_input= valid_transformer, transform_target=valid_transformer)\n",
    "valid_dataset = dataset2d.SegmentationDataset(input_root=f'{valid_dir}/images/',target_root=f'{valid_dir}/labels/',\n",
    "                               transform_input= valid_transformer, transform_target=valid_transformer)\n",
    "test_dataset = dataset2d.SegmentationDataset(input_root=f'{test_dir}/images/',target_root=f'{test_dir}/labels/',\n",
    "                               transform_input= valid_transformer, transform_target=valid_transformer)\n",
    "t_dataset = ConcatDataset([plain_train_dataset, aug1_dataset, aug2_dataset])\n",
    "\n",
    "# Loaders\n",
    "# train_loader = DataLoader(t_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_dataset = ConcatDataset([plain_train_dataset, aug1_dataset, aug2_dataset])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(\"Number of images, training:\", len(train_loader.dataset), \", validation\", len(valid_loader.dataset), \" testing:\", len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            images, masks = batch\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            iou = util_functions.calculate_IoU(outputs, masks)\n",
    "            total_iou += iou.item()\n",
    "            dice_value = util_functions.dice_coefficient(loss.item())\n",
    "        \n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        avg_iou = total_iou / len(data_loader)\n",
    "    return avg_loss, avg_iou, dice_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(n_epochs, model, optimizer, train_loader, valid_loader, device,\n",
    "                                criterion1, scheduler=None):\n",
    "    \n",
    "    model = model.to(device)\n",
    "        \n",
    "    best_valid_loss = np.Inf\n",
    "\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    valid_iou_list = []\n",
    "    valid_dice_list = []\n",
    "\n",
    "    results_folder = util_functions.create_result_folder(path='results')\n",
    "    print(results_folder)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss = util_functions.train_fn(data_loader=train_loader, model=model, criterion=criterion1, \n",
    "                              optimizer=optimizer, device=device)\n",
    "        valid_loss, valid_iou, valid_dice = eval_fn(data_loader=valid_loader, model=model, criterion=criterion1,\n",
    "                                        device=device)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Access the current learning rate\n",
    "        current_lr = scheduler.get_lr()[0]\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_iou_list.append(valid_iou)\n",
    "        valid_dice_list.append(valid_dice)\n",
    "        \n",
    "        if best_valid_loss > valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            directory = 'results'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save(model.state_dict(), f'{results_folder}/best_model.pt')\n",
    "            print('SAVED-MODEL')\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Valid IoU: {valid_iou}, lr: {current_lr}')\n",
    "        if epoch % 10 == 0:\n",
    "            util_functions.visualize_training(train_loss_list=train_loss_list, valid_loss_list=valid_loss_list,\n",
    "                                            valid_iou_list=valid_iou_list, valid_dice_list=valid_dice_list, results_folder=results_folder)\n",
    "            \n",
    "        lists_dict = {\n",
    "            'train_loss_list': train_loss_list,\n",
    "            'valid_loss_list': valid_loss_list,\n",
    "            'valid_iou_list': valid_iou_list,\n",
    "            'valid_dice_list': valid_dice_list,\n",
    "        }\n",
    "\n",
    "        with open(f'{results_folder}/training_trend.json', 'w') as f:\n",
    "            json.dump(lists_dict, f)\n",
    "        \n",
    "    return f'{results_folder}/best_model.pt'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "results/2023-12-14_13-43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = eff_unet2.EffUNet(in_channels=1, classes=1)\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "model.to(device)\n",
    "criterion1 = DiceLoss(mode=\"binary\")\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau()\n",
    "n_epochs = 21\n",
    "\n",
    "result_folder = train_loop(n_epochs, model, optimizer, train_loader, valid_loader, device, criterion1, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/2023-11-15_15-32/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "print(result_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
