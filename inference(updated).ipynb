{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils import mypreprocess, util_functions, eff_unet2, dataset2d\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'results/2023-12-14_13-43/best_model.pt' \n",
    "model = eff_unet2.EffUNet(in_channels=1, classes=1)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 1\n",
    "base_path = '/scratch/student/sinaziaee/datasets/2d_dataset/'\n",
    "train_dir = os.path.join(base_path, 'training')\n",
    "valid_dir = os.path.join(base_path, 'validation')\n",
    "test_dir = os.path.join(base_path, 'testing')\n",
    "\n",
    "inference_transformer = transforms.Compose([transforms.ToTensor(), \n",
    "                                            transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True)])\n",
    "\n",
    "test_dataset = dataset2d.SegmentationDataset(input_root=f'{test_dir}/images/',target_root=f'{test_dir}/labels/',\n",
    "                               transform_input= inference_transformer, transform_target=inference_transformer, with_path=True)\n",
    "inference_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_size: 1063, batch: torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset_size: {len(inference_loader.dataset)}, batch: {next(iter(inference_loader))[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1063 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0072 0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in tqdm(enumerate(inference_loader), total=len(inference_loader)):\n",
    "    each1, each2, path = batch\n",
    "    path = path[0]\n",
    "    img_idx = path[-13:-9]\n",
    "    slice_idx = path[-8:-4]\n",
    "    print(img_idx, slice_idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1063it [00:59, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall IoU: 0.45, Overall Dice Score: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save predictions only\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "def save_prediction(prediction, path, filename, output_size=(512, 512)):\n",
    "    \"\"\"Save the prediction mask as a PNG file with a specific size.\"\"\"\n",
    "    # Resize prediction to the desired output size\n",
    "    resized_prediction = cv2.resize(prediction, output_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(resized_prediction, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(path, filename), bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "total_iou = 0.0\n",
    "total_dice = 0.0\n",
    "num_images = 0\n",
    "\n",
    "# Define the 2D predictions folder\n",
    "predictions_folder = 'preds/2d_predictions'\n",
    "os.makedirs(predictions_folder, exist_ok=True)\n",
    "model = model.to(device)\n",
    "# Process each image and mask in the dataset\n",
    "for idx, (images, true_masks, path) in tqdm(enumerate(inference_loader)):\n",
    "    path = path[0]\n",
    "    images = images.to(device)\n",
    "    true_masks = true_masks.to(device)\n",
    "    image_index = path[-13:-9]\n",
    "    slice_index = path[-8:-4]\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        logits_mask = model(images)\n",
    "        pred_mask = torch.sigmoid(logits_mask)\n",
    "        # Ensure we are extracting a single 2D slice\n",
    "        pred_mask_cpu = (pred_mask > 0.5).float().cpu().numpy()[0, 0, :, :]\n",
    "\n",
    "    # Calculate IoU and Dice Score\n",
    "    iou = util_functions.calculate_IoU(pred_mask, true_masks)\n",
    "    dice_score = util_functions.dice_coefficient2_modified(true_masks, pred_mask)\n",
    "\n",
    "    total_iou += iou.item()\n",
    "    total_dice += dice_score\n",
    "    num_images += 1\n",
    "\n",
    "    # Save the prediction mask\n",
    "    save_filename = f'image_{image_index}_{slice_index}.png'\n",
    "    save_prediction(pred_mask_cpu, predictions_folder, save_filename)\n",
    "\n",
    "# Calculate and print the overall IoU and Dice Score\n",
    "overall_iou = total_iou / num_images\n",
    "overall_dice = total_dice / num_images\n",
    "print(f\"Overall IoU: {overall_iou:.2f}, Overall Dice Score: {overall_dice:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D NIfTI files created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_combine_slices_to_nifti(png_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Dictionary to hold slices for each image\n",
    "    image_slices = {}\n",
    "\n",
    "    # Iterate over PNG files and group slices by image\n",
    "    for file in sorted(os.listdir(png_folder)):\n",
    "        if file.endswith('.png'):\n",
    "            parts = file.split('_')\n",
    "            image_index = int(parts[1])\n",
    "            slice_index = int(parts[2].split('.')[0])\n",
    "            slice_path = os.path.join(png_folder, file)\n",
    "            slice_data = io.imread(slice_path, as_gray=True)\n",
    "\n",
    "            if image_index not in image_slices:\n",
    "                image_slices[image_index] = {}\n",
    "            image_slices[image_index][slice_index] = slice_data\n",
    "\n",
    "    # Process each image group\n",
    "    for image_index in image_slices:\n",
    "        slices = [image_slices[image_index][i] for i in sorted(image_slices[image_index])]\n",
    "        image_3d = np.stack(slices, axis=-1)\n",
    "\n",
    "        # Save as NIfTI file\n",
    "        nifti_path = os.path.join(output_folder, f'image_{image_index:04d}.nii.gz')\n",
    "        nifti_img = nib.Nifti1Image(image_3d, np.eye(4))\n",
    "        nib.save(nifti_img, nifti_path)\n",
    "\n",
    "    print(\"3D NIfTI files created.\")\n",
    "\n",
    "# Example usage\n",
    "png_folder = 'preds/2d_predictions'\n",
    "output_folder = 'preds/3d_predictions'\n",
    "load_and_combine_slices_to_nifti(png_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
